{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0008556c-2809-4686-b7b7-16c7d68bb8db",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Neural networks using MLPClassifier of sklearn.neural_network module\n",
    "\n",
    "### Classifying (recognizing) hand-written digits using neural networks\n",
    "\n",
    "### Objectives\n",
    "\n",
    "On completing this assignment, students will be able to write a simple AI application for classifying (recognizing) hand-written digits using neural networks.\n",
    "\n",
    "\n",
    "### Readings for Neural Networks\n",
    "\n",
    "#### Required Reading: Introduction\n",
    "\n",
    "https://www.ibm.com/topics/neural-networks#:~:text=One%20of%20the%20best%2Dknown,heart%20of%20deep%20learning%20models.\n",
    "\n",
    "#### Optional Reading: Backpropagation\n",
    "\n",
    "https://www.geeksforgeeks.org/backpropagation-in-neural-network\n",
    "\n",
    "#### Required Reading: Code Example\n",
    "\n",
    "https://www.pluralsight.com/resources/blog/guides/machine-learning-neural-networks-scikit-learn#:~:text=In%20this%20guide%2C%20you%20have,training%20and%20test%20data%2C%20respectivetiv\n",
    "\n",
    "\n",
    "### Assignment\n",
    " \n",
    "Write an AI application which will classify hand-written digits into numerals 0 to 9 using neural networks. This application is similar to the one you did previously. However, in this application, each image is represented with 28 by 28 pixels (instead of with 8 by 8 pixels). The data used in this application and steps to follow to write the application are outlined below.\n",
    "\n",
    "### Loading data set and viewing its values\n",
    "\n",
    "The data used in this assignment is provided in the following two files.\n",
    "\n",
    "    images.pkl\n",
    "    targets.pkl\n",
    "\n",
    "The first file contains an array of shape = (60000, 28, 28). The second file contains an array of shape (60000,). We extract these arrays from the above files and store their contents into variables images and target. Then display different characteristics of those variables as shown in the code below. \n",
    "\n",
    "    \n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    f = open (\"images.pkl\", 'rb')\n",
    "    images = pickle.load(f)\n",
    "    f.close()\n",
    "    f = open (\"target.pkl\", 'rb')\n",
    "    target = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print (type (images))\n",
    "    print (type (target))\n",
    "    print(images.shape)\n",
    "    print(target.shape)\n",
    "    print (images[0])\n",
    "    print (target)\n",
    "    print (target[0])\n",
    "\n",
    "\n",
    "    The output of the above code is below:\n",
    "\n",
    "    <class 'numpy.ndarray'>\n",
    "    <class 'numpy.ndarray'>\n",
    "    (60000, 28, 28)\n",
    "    (60000,)\n",
    "    [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0] \n",
    "    [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251 93  82  82  56  39   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241 0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154 0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119 25   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201 78   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]\n",
    "     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
    "    0   0   0   0   0   0   0   0   0   0]]\n",
    "    \n",
    "    [5 0 4 ... 5 6 8]\n",
    "    5\n",
    "\n",
    "\n",
    "### Results of viewing the above output\n",
    "\n",
    "By studying the above output, we conclude the following:\n",
    "\n",
    "- The arrays, images and target, are numpy arrays\n",
    "- The shape of array images is (60000, 28, 28). So, the array contains 60000 images and each image is 28 by 28 two dimensional array.\n",
    "- The array target is a one dimensional array and it contains integers, varying in values between 0 and 9 and these values correspond to images stored in array images. Above, when we display the first element of target array, it is 5. Below, we display the first image in array images and it is an image of 5. See below.\n",
    "\n",
    "#### Displaying an image\n",
    "\n",
    "Below, we display the first image in array images.\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.matshow(images[0])\n",
    "\n",
    "The image shown by above code would be the image of 5.\n",
    "\n",
    "#### Conclusions from above\n",
    "\n",
    "From above, we conclude the following: \n",
    "\n",
    "- We should leave the array target as it is and use it for target values\n",
    "- We should also leave the array images as it is and use it for displaying images with matplotlib.pyplot or plt as shown above.\n",
    "- Using array images of shape (60000, 28, 28), we should create another array named data_flat of shape (60000, 784) (where 784 = 28 * 28) by simply reshaping the array images. This would make each image to be a one dimensional array of size 784 containing 784 pixel values and we would be able to use those image values as input to neural networks. (Neural networks require that their inputs be flat or one dimensional). Below, we create the array data_flat.\n",
    "\n",
    "\n",
    "#### Create flat array\n",
    "\n",
    "Below, we reshape the array images of shape = (60000, 28, 28) into an array of shape = (6000 , 784) and save it as array data_flat.                     \n",
    "\n",
    "    data_flat = images.reshape(len(images),28 *28)\n",
    "    print (data_flat.shape)\n",
    "\n",
    "    output from above:\n",
    "    (60000, 784)\n",
    "    \n",
    "\n",
    "#### Normalizing the flat array\n",
    "\n",
    "The pixel values in array data_flat vary from 0 to 255. We should normalize this array by dividing each of its values by 255. So, the values of converted array data_flat_norm will vary from 0 to 1. Since, data_flat is a numpy array, we can accomplish this in single step as shown in the code below. We also display the values of one element of the converted array, data_flat_norm, to check that our method worked. (In neural networks, we normalize values because it usually improves performance.)\n",
    "\n",
    "\n",
    "    data_flat_norm = data_flat/255\n",
    "    print(data_flat_norm[0])\n",
    "\n",
    "    The output from the above: \n",
    "[0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
    " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
    " 0.96862745 0.49803922 0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
    " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
    " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.19215686\n",
    " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
    " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
    " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
    " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
    " 0.96862745 0.94509804 0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
    " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.04313725\n",
    " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.1372549  0.94509804\n",
    " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
    " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
    " 0.58823529 0.10588235 0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
    " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.15294118 0.58039216\n",
    " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
    " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
    " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.07058824 0.67058824\n",
    " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
    " 0.31372549 0.03529412 0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
    " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.53333333 0.99215686\n",
    " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.         0.         0.\n",
    " 0.         0.         0.         0.        ]\n",
    "\n",
    "\n",
    "#### Splitting data into training and test data\n",
    "\n",
    "Split the arrays, data_flat_norm and target, into training data and testing data, with 20% (0.20) for testing and the remaining for training, using train_test_split function from sklearn.preprocessing module.\n",
    "\n",
    "#### Training MLPClassifier classifier from sklearn.neural_network module\n",
    "\n",
    "Train MLPClassifier classifier with the training data (X_train) and its corresponding label data (y_train) from the previous step using the following attribute values for MLPClassifier.\n",
    "\n",
    "    hidden_layer_sizes = (30, )\n",
    "    max_iter = 50\n",
    "    learning_rate_init = 0.05\n",
    "    verbose = 1\n",
    "    random_state = 1\n",
    "\n",
    "    \n",
    "#### Display score for training and testing values\n",
    "\n",
    "\n",
    "\n",
    "#### Display accuracy_score, classification report, and confusion_matrix\n",
    "\n",
    "    \n",
    "\n",
    "#### Experiments\n",
    "\n",
    "You are to do the following three experiments:\n",
    "\n",
    "__Experiment 1__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    max_iter = 50\n",
    "    learning_rate_init = 0.05\n",
    "\n",
    "Change first hidden laye sizes as below and record the corresponding accuracy score:\n",
    "\n",
    "    hidden layer sizes = (30,)    accuracy score = \n",
    "    hidden layer sizes = (50,)   accuracy score =\n",
    "    hidden layer sizes = (70,)   accuracy score = \n",
    "\n",
    "__Experiment 2__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    max_iter = 50\n",
    "    hidden layer sizes = (30,)\n",
    "\n",
    "Change the learning rate as below and record the corresponding accuracy score:\n",
    "\n",
    "    learning rate = 0.05   accuracy score = \n",
    "    learning rate = 0.1    accuracy score = \n",
    "\n",
    "__Experiment 3__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    hidden layer sizes = (30,)\n",
    "    learning rate = 0.05\n",
    "\n",
    "Change the max_iter as below and record the corresponding accuracy score:\n",
    "\n",
    "    max_iter = 25    accuracy score = \n",
    "    max_iter = 50   accuracy score = \n",
    "    max_iter = 75   accuracy score =\n",
    "\n",
    "__Summary Report__\n",
    "\n",
    "Write a short paragraph summarizing the above results and what you learn about AI from the above experiments,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1b45d",
   "metadata": {},
   "source": [
    "## Title: ANN Digit Classification Using MLPClassifier\n",
    "\n",
    "### Keith Yrisarri Stateson\n",
    "July 18, 2024. Python 3.11.0\n",
    "\n",
    "##### Summary\n",
    "This assignment involves building an Artificial Neural Network (ANN) to classify handwritten digits from the MNIST dataset using the MLPClassifier from Scikit-learn's neural_network module. The goal is to develop a model that can accurately recognize and classify images of digits (0-9). The assignment includes steps such as loading and preprocessing the data, building and training the model, evaluating its performance, and conducting experiments to optimize the model's parameters.\n",
    "\n",
    "Assumptions\n",
    "The dataset comprises images and their corresponding labels stored in images.pkl and targets.pkl. The input images are 28x28 pixels in size and need to be flattened for input into the neural network. Normalization of pixel values (0-255) to a range of 0-1 improves the performance of the neural network. The MLPClassifier is suitable for this classification task and can be optimized through experimentation with different parameters.\n",
    "\n",
    "##### Summary\n",
    "Data Loading and Exploration\n",
    "- Importing Libraries\n",
    "- Loading the Dataset\n",
    "- Exploring the Data\n",
    "\n",
    "Data Preprocessing\n",
    "- Reshaping Images\n",
    "- Normalizing Pixel Values\n",
    "- Splitting Data into Training and Test Sets\n",
    "\n",
    "Building the ANN Model\n",
    "- Model Architecture\n",
    "- Compiling the Model\n",
    "\n",
    "Training the Model\n",
    "- Training Process\n",
    "- Monitoring Training Performance\n",
    "\n",
    "Evaluating the Model\n",
    "- Model Evaluation Metrics\n",
    "- Accuracy and Loss Visualization\n",
    "- Confusion Matrix Analysis\n",
    "\n",
    "Experiments\n",
    "- Experiment 1: Varying Hidden Layer Sizes\n",
    "- Experiment 2: Changing Learning Rates\n",
    "- Experiment 3: Adjusting Maximum Iterations\n",
    "\n",
    "Results and Discussion\n",
    "- Summary of Experiment Results\n",
    "- Insights and Observations\n",
    "\n",
    "Conclusion\n",
    "- Summary of findings\n",
    "- Future improvements and considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f81b9-3645-4888-9c7c-74208ea3cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
