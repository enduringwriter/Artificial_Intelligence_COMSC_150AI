{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf22276-e63e-401b-b1c0-6a1db481c693",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Neural networks using MLPClassifier from sklearn.neural_network module\n",
    "\n",
    "### Classifying (Recognizing) Hand-written Digits using neural networks\n",
    "\n",
    "### Objectives\n",
    "\n",
    "On completing this assignment, students will be able to write a simple AI application for classifying (Recognizing) hand-written digits using neural networks.\n",
    "\n",
    "### Readings for Neural Networks\n",
    "\n",
    "#### Required Reading: Introduction\n",
    "\n",
    "https://www.ibm.com/topics/neural-networks#:~:text=One%20of%20the%20best%2Dknown,heart%20of%20deep%20learning%20models.\n",
    "\n",
    "#### Optional Reading: Backpropagation\n",
    "\n",
    "https://www.geeksforgeeks.org/backpropagation-in-neural-network\n",
    "\n",
    "#### Required Reading: Code Example\n",
    "\n",
    "https://www.pluralsight.com/resources/blog/guides/machine-learning-neural-networks-scikit-learn#:~:text=In%20this%20guide%2C%20you%20have,training%20and%20test%20data%2C%20respectivetiv\n",
    "\n",
    "### Additionally do the following\n",
    "\n",
    "For training and testing the application, we use MLPClassifier classifier from sklearn.neural_network module as shown in the code fragment below. \n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    clf=MLPClassifier(hidden_layer_sizes=(64, 10), max_iter=200, learning_rate_init=0.05, verbose=1, random_state=1)\n",
    "    \n",
    "The above MLPClassifier classifier will employs neural networks during training. In neural networks, the input layer size is always the same as the number of inputs and the output layer size is always the same as the number of outputs. \n",
    "\n",
    "In this case, since each digit is represented by 64 (8 by 8) pixel values, the input layer size will be 64. Since digits are to be classified into 10 different numerals from 0 to 9, the output layer size will be 10.\n",
    "\n",
    "We chose, two hidden layers as indicated in the code fragment above (64,10). We chose the first hidden layer size to be 64 (the same as the input layer size) and the second hidden layer size to be 10 (the same as the output layer size). \n",
    "\n",
    "We chose maximum iteration to be 200 as shown in code fragment above. So, during training, the classifier (clf) will run the same data 200 times. It will randomly select its internal weight parameter values at the beginning the of first run and then adjust these values at the end of each run in an attempt to reduce the loss (error) (the difference between the actual output values and the true values) for the next run. \n",
    "\n",
    "We chose learning rate to be 0.05 in the code fragment above. So, the classifier will multiply the loss value with 0.05 to decide on how much to try to reduce the loss for the next run. With a smaller learning rate (such as 0.01), it will try to reduce loss by smaller amount and for a larger learning rate (such as 0.1), it will try to reduce the loss by a smaller amount at each run in an attempt to get a loss approaching zero.\n",
    "\n",
    "We chose verbose to be 1 (or True) in the above code fragment in order to initiate printing of details such as the loss value after each run.\n",
    "\n",
    "We chose to specify the value for random_state in the above code fragment, to ensure that the classifier would start from the same random state at each execution of the application and its behavior will be consistent at each run of the application. This will allow us to experiment with different parameter values while keeping the classifier behavior consistent.\n",
    "\n",
    "#### Experiments\n",
    "   \n",
    "You are to do the following three experiments:\n",
    "\n",
    "__Experiment 1__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    max_iter = 200\n",
    "    learning_rate_init = 0.05\n",
    "\n",
    "Change the hidden layer sizes as below and record the corresponding accuracy score:\n",
    "\n",
    "    hidden_layer_sizes = (50,10)    accuracy score =\n",
    "    hidden_layer_sizes = (100,10)   accuracy score =\n",
    "    hidden_layer_sizes = (200,10)   accuracy score = \n",
    "\n",
    "__Experiment 2__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    max_iter = 200\n",
    "    hidden_layer_size = (100,10)\n",
    "\n",
    "Change the learning rate as below and record the corresponding accuracy score:\n",
    "\n",
    "    learning_rate_init = 0.01   accuracy score =\n",
    "    learning_rate_init = 0.05   accuracy score =\n",
    "    learning_rate_init = 0.1    accuracy score = \n",
    "\n",
    "__Experiment 3__\n",
    "\n",
    "Keep the following values fixed\n",
    "\n",
    "    hidden_layer_sizes = (100,10)\n",
    "    learning_rate_init = 0.05\n",
    "\n",
    "Change the max_iter as below and record the corresponding accuracy score:\n",
    "\n",
    "    max_iter = 50    accuracy score = \n",
    "    max_iter = 100   accuracy score = \n",
    "    max_iter = 200   accuracy score =\n",
    "\n",
    "__Summary Report__\n",
    "\n",
    "Write a short paragraph summarizing the above results and what you learn about AI from the above experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b9a91",
   "metadata": {},
   "source": [
    "## Title: Artificial Neural Network (ANN) Digit Classification\n",
    "\n",
    "### Keith Yrisarri Stateson\n",
    "July 18, 2024. Python 3.11.0\n",
    "\n",
    "##### Summary\n",
    "The assignment focuses on building an Artificial Neural Network (ANN) to classify handwritten digits from the MNIST dataset. The objective is to train a Artificial Neural Network (ANN) model to recognize and classify images of digits (0-9). This is achieved by using the MLPClassifier by scikit-learn. MLP means multi-layer perceptron, a type of artificial neural network designed for supervised learning tasks, particularly classification.\n",
    "\n",
    "Common Parameters:\n",
    "- hidden_layer_sizes: Tuple indicating the number of neurons in each hidden layer (e.g., (100,) for one hidden layer with 100 neurons).\n",
    "- activation: Activation function for the hidden layers (default is 'relu').\n",
    "- solver: The optimizer for weight optimization (default is 'adam').\n",
    "- learning_rate_init: Initial learning rate used (default is 0.001).\n",
    "- max_iter: Maximum number of iterations for training (default is 200).\n",
    "- verbose: Controls the verbosity of the output during training.\n",
    "\n",
    "Assumptions: None.\n",
    "\n",
    "##### Table of Contents\n",
    "Data Preprocessing\n",
    "- Loading the MNIST dataset\n",
    "- Normalizing the data\n",
    "- Reshaping the data for the neural network\n",
    "\n",
    "Building the ANN Model\n",
    "- Model architecture\n",
    "\n",
    "Training the Model\n",
    "- Training process\n",
    "- Monitoring training performance\n",
    "- Handling overfitting\n",
    "\n",
    "Evaluating the Model\n",
    "- Model evaluation metrics\n",
    "- Accuracy and loss visualization\n",
    "- Confusion matrix analysis\n",
    "\n",
    "Experiments\n",
    "- Adjust hyperparameters\n",
    "\n",
    "Conclusion\n",
    "- Summary of findings\n",
    "\n",
    "##### Questions\n",
    "- How do Make Predictions?\n",
    "    - Using the trained model for predictions\n",
    "    - Visualizing predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e360d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37f8b326-cc82-49f1-ad21-7ddd641bf53d",
   "metadata": {},
   "source": [
    "Load digit data set from sklearn's datasets module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9c968f-a5fd-437e-af4b-282f9564596b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "digits=datasets.load_digits()\n",
    "dir (digits)  # to see the attributes of the dataset and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13e28d-a8eb-414b-a96b-151da083afdd",
   "metadata": {},
   "source": [
    "from digit data set extract data, images, and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc09dd6-d195-4e3f-9240-9bcebdaaa721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1797, 64)\n",
      "(1797, 8, 8)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "data = digits.data\n",
    "images = digits.images\n",
    "target = digits.target  # the target is the number that the image represents\n",
    "print (type (data))\n",
    "print (type (images))\n",
    "print (type (target))\n",
    "print (data.shape)\n",
    "print (images.shape)\n",
    "print (target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb234133-04cc-42d3-ada9-6f2b8dc7ea13",
   "metadata": {},
   "source": [
    "Display first element of data, images, and target arrays and show the first element of images as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d873ce39-73f7-461a-b496-2b816376a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137ca7fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print (data[0])\n",
    "print (images[0])\n",
    "print (target[0])\n",
    "plt.matshow(images[0])  # to display the first image\n",
    "# plt.imshow(images[0], cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082beed-3ddc-4c2f-ba1c-88f43d496e01",
   "metadata": {},
   "source": [
    "So, from the above, it is clear that the elements of data, images, and target arrays carry data about images in different form and each element of the arrays contains data about one image as indicated below:\n",
    "\n",
    "- An element of data array contains 64 pixel values in one dimension array \n",
    "- An element of images array contains the same pixel values as an 8 by 8 two dimensional array (So, we were able to show it in image form using  plt)\n",
    "- An element of target contains the information about the image as an int\n",
    "\n",
    "We will leave images array as it is and simply use it for displaying images.\n",
    "\n",
    "We will use data array for processing. Since, the pixel values vary form 0 (black) to 255 (black), we will normalize them (bring them in the range from 0 to 1) by dividing each by 255. Since, it is a numpy array, we can divide each value in the whole array in a single step and store it in a variable data_flat_norm (the name indicates that the array elements are one dimensional (or flat) and they are normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5036d6-7bb4-475f-8fa1-b94d7e6fa515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.01960784, 0.05098039, 0.03529412,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05098039, 0.05882353, 0.03921569, 0.05882353, 0.01960784,\n",
       "        0.        , 0.        , 0.01176471, 0.05882353, 0.00784314,\n",
       "        0.        , 0.04313725, 0.03137255, 0.        , 0.        ,\n",
       "        0.01568627, 0.04705882, 0.        , 0.        , 0.03137255,\n",
       "        0.03137255, 0.        , 0.        , 0.01960784, 0.03137255,\n",
       "        0.        , 0.        , 0.03529412, 0.03137255, 0.        ,\n",
       "        0.        , 0.01568627, 0.04313725, 0.        , 0.00392157,\n",
       "        0.04705882, 0.02745098, 0.        , 0.        , 0.00784314,\n",
       "        0.05490196, 0.01960784, 0.03921569, 0.04705882, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02352941, 0.05098039,\n",
       "        0.03921569, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.04705882, 0.05098039,\n",
       "        0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.0627451 , 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01176471, 0.05882353,\n",
       "        0.0627451 , 0.02352941, 0.        , 0.        , 0.        ,\n",
       "        0.02745098, 0.05882353, 0.0627451 , 0.0627451 , 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.0627451 , 0.0627451 , 0.01176471, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.0627451 , 0.0627451 ,\n",
       "        0.02352941, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.0627451 , 0.0627451 , 0.02352941, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04313725,\n",
       "        0.0627451 , 0.03921569, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.01568627, 0.05882353,\n",
       "        0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.0627451 , 0.05882353, 0.05490196, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03137255, 0.05098039,\n",
       "        0.03137255, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.02352941, 0.05882353, 0.04313725,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.03137255,\n",
       "        0.05098039, 0.05882353, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.03529412, 0.0627451 , 0.0627451 , 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "        0.05098039, 0.0627451 , 0.0627451 , 0.04313725, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "        0.04313725, 0.0627451 , 0.03529412, 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flat_norm = data/255\n",
    "data_flat_norm[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ec6e2-fae4-4a50-bb49-761a85b825a3",
   "metadata": {},
   "source": [
    "Split the data in data_flat_norm into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbe6467-40be-473e-b4a8-ff7e905e1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.03529412 0.05882353 0.00784314\n",
      " 0.         0.         0.         0.         0.01960784 0.0627451\n",
      " 0.04313725 0.00392157 0.         0.         0.         0.\n",
      " 0.05098039 0.05882353 0.00392157 0.         0.         0.\n",
      " 0.         0.00784314 0.0627451  0.04313725 0.         0.\n",
      " 0.         0.         0.         0.00784314 0.0627451  0.04313725\n",
      " 0.01568627 0.01568627 0.         0.         0.         0.00784314\n",
      " 0.05882353 0.0627451  0.0627451  0.05490196 0.03921569 0.00392157\n",
      " 0.         0.         0.03529412 0.0627451  0.02745098 0.01176471\n",
      " 0.05882353 0.02352941 0.         0.         0.         0.02745098\n",
      " 0.05882353 0.0627451  0.0627451  0.02352941]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data_flat_norm, target, test_size=0.2, random_state=0)\n",
    "\n",
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc8423-5b23-496b-9e67-8cc9561b7d2d",
   "metadata": {},
   "source": [
    "Create MLPClassifier classifier for neural network training and set its parameters as below.\n",
    "\n",
    "- hidden_layer_sizes is used to indicate the number of hidden layers and the number of computing units in each hidden layer\n",
    "- max_iter is used to indicate the number of times to do the training with the same test data, each time changing the internal weight parameter values in the direction of reducing the loss.\n",
    "- verbose A value of True or 1 request that the details such as loss values be displayed after each run. \n",
    "-random_state By specifying the same random_state value each time you run the classifier, you are ensuring that the same sequence of events will occur each time. This can be helpful in debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab752b1",
   "metadata": {},
   "source": [
    "## Build the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f0e219c-a8f0-437d-af72-af80114dffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Artificial Neural Network (ANN) model\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf=MLPClassifier(hidden_layer_sizes=(64, 10), max_iter=200, learning_rate_init=0.05, verbose=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267131c3-8c9c-4bd7-b88c-e80ba08b8218",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063426ee",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabe0ddf-6489-4073-af62-fd9b5063da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30421014\n",
      "Iteration 2, loss = 2.10670810\n",
      "Iteration 3, loss = 1.84612755\n",
      "Iteration 4, loss = 1.47339401\n",
      "Iteration 5, loss = 1.10939035\n",
      "Iteration 6, loss = 0.93026683\n",
      "Iteration 7, loss = 0.93243884\n",
      "Iteration 8, loss = 0.81634669\n",
      "Iteration 9, loss = 0.75415133\n",
      "Iteration 10, loss = 0.68509135\n",
      "Iteration 11, loss = 0.67650182\n",
      "Iteration 12, loss = 0.61864945\n",
      "Iteration 13, loss = 0.60401945\n",
      "Iteration 14, loss = 0.58176095\n",
      "Iteration 15, loss = 0.59163216\n",
      "Iteration 16, loss = 0.51643214\n",
      "Iteration 17, loss = 0.49754356\n",
      "Iteration 18, loss = 0.47375272\n",
      "Iteration 19, loss = 0.47018774\n",
      "Iteration 20, loss = 0.47247387\n",
      "Iteration 21, loss = 0.41392364\n",
      "Iteration 22, loss = 0.41937124\n",
      "Iteration 23, loss = 0.39347308\n",
      "Iteration 24, loss = 0.36090958\n",
      "Iteration 25, loss = 0.36226367\n",
      "Iteration 26, loss = 0.39116833\n",
      "Iteration 27, loss = 0.35710670\n",
      "Iteration 28, loss = 0.36513030\n",
      "Iteration 29, loss = 0.34982524\n",
      "Iteration 30, loss = 0.35746274\n",
      "Iteration 31, loss = 0.33690817\n",
      "Iteration 32, loss = 0.30263923\n",
      "Iteration 33, loss = 0.29332494\n",
      "Iteration 34, loss = 0.29103495\n",
      "Iteration 35, loss = 0.27839259\n",
      "Iteration 36, loss = 0.26509278\n",
      "Iteration 37, loss = 0.26110502\n",
      "Iteration 38, loss = 0.25410178\n",
      "Iteration 39, loss = 0.26250161\n",
      "Iteration 40, loss = 0.24354357\n",
      "Iteration 41, loss = 0.23368341\n",
      "Iteration 42, loss = 0.23235105\n",
      "Iteration 43, loss = 0.23812641\n",
      "Iteration 44, loss = 0.23011445\n",
      "Iteration 45, loss = 0.25472374\n",
      "Iteration 46, loss = 0.27219303\n",
      "Iteration 47, loss = 0.23973114\n",
      "Iteration 48, loss = 0.20963630\n",
      "Iteration 49, loss = 0.21442351\n",
      "Iteration 50, loss = 0.21048664\n",
      "Iteration 51, loss = 0.20586002\n",
      "Iteration 52, loss = 0.21878596\n",
      "Iteration 53, loss = 0.21258287\n",
      "Iteration 54, loss = 0.20756431\n",
      "Iteration 55, loss = 0.19348276\n",
      "Iteration 56, loss = 0.21613260\n",
      "Iteration 57, loss = 0.19723256\n",
      "Iteration 58, loss = 0.20219723\n",
      "Iteration 59, loss = 0.18738906\n",
      "Iteration 60, loss = 0.18384767\n",
      "Iteration 61, loss = 0.19299826\n",
      "Iteration 62, loss = 0.22541226\n",
      "Iteration 63, loss = 0.21843696\n",
      "Iteration 64, loss = 0.19314920\n",
      "Iteration 65, loss = 0.21712278\n",
      "Iteration 66, loss = 0.18458654\n",
      "Iteration 67, loss = 0.16509418\n",
      "Iteration 68, loss = 0.18853874\n",
      "Iteration 69, loss = 0.21406324\n",
      "Iteration 70, loss = 0.16938074\n",
      "Iteration 71, loss = 0.16809055\n",
      "Iteration 72, loss = 0.15719367\n",
      "Iteration 73, loss = 0.15222753\n",
      "Iteration 74, loss = 0.15304945\n",
      "Iteration 75, loss = 0.16697205\n",
      "Iteration 76, loss = 0.15368769\n",
      "Iteration 77, loss = 0.14523191\n",
      "Iteration 78, loss = 0.15744889\n",
      "Iteration 79, loss = 0.13966181\n",
      "Iteration 80, loss = 0.21448747\n",
      "Iteration 81, loss = 0.17154046\n",
      "Iteration 82, loss = 0.14129746\n",
      "Iteration 83, loss = 0.15368842\n",
      "Iteration 84, loss = 0.15626162\n",
      "Iteration 85, loss = 0.14026644\n",
      "Iteration 86, loss = 0.12650421\n",
      "Iteration 87, loss = 0.13193079\n",
      "Iteration 88, loss = 0.12452374\n",
      "Iteration 89, loss = 0.12457683\n",
      "Iteration 90, loss = 0.13056548\n",
      "Iteration 91, loss = 0.13276045\n",
      "Iteration 92, loss = 0.12244382\n",
      "Iteration 93, loss = 0.11999311\n",
      "Iteration 94, loss = 0.10944904\n",
      "Iteration 95, loss = 0.10867957\n",
      "Iteration 96, loss = 0.11112730\n",
      "Iteration 97, loss = 0.12196614\n",
      "Iteration 98, loss = 0.11893110\n",
      "Iteration 99, loss = 0.11006301\n",
      "Iteration 100, loss = 0.10337204\n",
      "Iteration 101, loss = 0.11263667\n",
      "Iteration 102, loss = 0.10970136\n",
      "Iteration 103, loss = 0.09837782\n",
      "Iteration 104, loss = 0.09785997\n",
      "Iteration 105, loss = 0.10253246\n",
      "Iteration 106, loss = 0.10002161\n",
      "Iteration 107, loss = 0.10066076\n",
      "Iteration 108, loss = 0.09834383\n",
      "Iteration 109, loss = 0.08732736\n",
      "Iteration 110, loss = 0.09979496\n",
      "Iteration 111, loss = 0.12233312\n",
      "Iteration 112, loss = 0.10338355\n",
      "Iteration 113, loss = 0.12392667\n",
      "Iteration 114, loss = 0.10580012\n",
      "Iteration 115, loss = 0.10609026\n",
      "Iteration 116, loss = 0.09303700\n",
      "Iteration 117, loss = 0.08835531\n",
      "Iteration 118, loss = 0.07998605\n",
      "Iteration 119, loss = 0.07735666\n",
      "Iteration 120, loss = 0.08165152\n",
      "Iteration 121, loss = 0.08314675\n",
      "Iteration 122, loss = 0.07998023\n",
      "Iteration 123, loss = 0.08512707\n",
      "Iteration 124, loss = 0.07858185\n",
      "Iteration 125, loss = 0.07262822\n",
      "Iteration 126, loss = 0.08276202\n",
      "Iteration 127, loss = 0.07182444\n",
      "Iteration 128, loss = 0.08378248\n",
      "Iteration 129, loss = 0.08722164\n",
      "Iteration 130, loss = 0.09429688\n",
      "Iteration 131, loss = 0.09098369\n",
      "Iteration 132, loss = 0.07680781\n",
      "Iteration 133, loss = 0.08897667\n",
      "Iteration 134, loss = 0.07502823\n",
      "Iteration 135, loss = 0.06419847\n",
      "Iteration 136, loss = 0.07284343\n",
      "Iteration 137, loss = 0.08037793\n",
      "Iteration 138, loss = 0.09562804\n",
      "Iteration 139, loss = 0.08675762\n",
      "Iteration 140, loss = 0.08748264\n",
      "Iteration 141, loss = 0.09563598\n",
      "Iteration 142, loss = 0.11499750\n",
      "Iteration 143, loss = 0.10216831\n",
      "Iteration 144, loss = 0.09377897\n",
      "Iteration 145, loss = 0.11400445\n",
      "Iteration 146, loss = 0.09701196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(64, 10), learning_rate_init=0.05,\n",
       "              random_state=1, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(64, 10), learning_rate_init=0.05,\n",
       "              random_state=1, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(64, 10), learning_rate_init=0.05,\n",
       "              random_state=1, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace7c48-b154-4674-a30c-90c91021e3cb",
   "metadata": {},
   "source": [
    "Since, the loss (error) (the difference between the true and predicted value) may not be zero at the end of training, calculate the classifier's score with the training data. Also, calculate its score with the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09976558-6985-4902-9719-5f4b390a4800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9679888656924147\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Scores range from 0 to 1, with a larger score indicating a better fit.\n",
    "# The score is computed as the fraction of correctly classified samples.\n",
    "\n",
    "# A difference between the training score and the test score is evidence of overfitting and can be reduced by decreasing the complexity of the model (e.g., the number of parameters) or by increasing the size of the training set.\n",
    "\n",
    "print(clf.score(X_train,y_train))\n",
    "print (clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "431da16b-441c-4039-af15-082987c60b7b",
   "metadata": {},
   "source": [
    "Also, print the accuracy_score, classification_report, and confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1df33",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06840e4-3108-431f-b9f9-2efa5c9756d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.84      0.91      0.88        35\n",
      "           2       0.97      0.92      0.94        36\n",
      "           3       0.90      0.90      0.90        29\n",
      "           4       0.88      1.00      0.94        30\n",
      "           5       0.97      0.82      0.89        40\n",
      "           6       0.98      0.98      0.98        44\n",
      "           7       0.97      0.79      0.87        39\n",
      "           8       0.68      0.87      0.76        39\n",
      "           9       0.82      0.76      0.78        41\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.90      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 32  0  0  0  0  1  0  2  0]\n",
      " [ 0  1 33  1  0  0  0  0  1  0]\n",
      " [ 0  0  1 26  0  0  0  0  2  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 33  0  0  1  6]\n",
      " [ 0  1  0  0  0  0 43  0  0  0]\n",
      " [ 0  0  0  0  4  0  0 31  3  1]\n",
      " [ 0  4  0  1  0  0  0  0 34  0]\n",
      " [ 0  0  0  1  0  1  0  1  7 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print (confusion_matrix (y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c52048",
   "metadata": {},
   "source": [
    "## Experiment 1 - adjusting hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed921ded-9980-4a38-b8a8-ab2ae09cb807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with hidden layer sizes: (50, 10)\n",
      "CLF Score on training set: 0.9868\n",
      "CLF Score on test set: 0.9278\n",
      "Accuracy score: 0.9278\n",
      "--------------------------------------------------\n",
      "Experiment with hidden layer sizes: (64, 10)\n",
      "CLF Score on training set: 0.9680\n",
      "CLF Score on test set: 0.8889\n",
      "Accuracy score: 0.8889\n",
      "--------------------------------------------------\n",
      "Experiment with hidden layer sizes: (100, 10)\n",
      "CLF Score on training set: 1.0000\n",
      "CLF Score on test set: 0.9417\n",
      "Accuracy score: 0.9417\n",
      "--------------------------------------------------\n",
      "Experiment with hidden layer sizes: (200, 10)\n",
      "CLF Score on training set: 0.9986\n",
      "CLF Score on test set: 0.9389\n",
      "Accuracy score: 0.9389\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assess accuracy of the model by adjusting the hidden_layer_sizes parameter\n",
    "\n",
    "# The hidden_layer_sizes parameter is a tuple that specifies the number of hidden layers and the number of neurons in each layer.\n",
    "\n",
    "# The verbose parameter in MLPClassifier controls the verbosity of the training process, meaning it determines whether the training progress is printed to the console. It does not affect the analysis or the performance of the model. It's purely for monitoring purposes.\n",
    "    # verbose=True (verbose=1): Prints the training progress to the console, including iteration number and loss.\n",
    "    # verbose=False (verbose=0): Suppresses the printing of training progress.\n",
    "    # verbose=0 results in a warning.\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) # when verbose=0\n",
    "\n",
    "hidden_layer_sizes = [(50, 10), (64, 10), (100, 10), (200, 10)]\n",
    "\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    clf=MLPClassifier(hidden_layer_sizes=hidden_layer_size, max_iter=200, learning_rate_init=0.05, verbose=0, random_state=1)\n",
    "    \n",
    "    clf.fit (X_train,y_train)\n",
    "    print(f'Experiment with hidden layer sizes: {hidden_layer_size}')\n",
    "    print(f'CLF Score on training set: {clf.score(X_train, y_train):.4f}')\n",
    "    print(f'CLF Score on test set: {clf.score(X_test, y_test):.4f}')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f'Accuracy score: {accuracy_score(y_test, y_pred):.4f}')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28eef70",
   "metadata": {},
   "source": [
    "## Experiment 2 - adjusting learning_rate_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21b64828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with learning rate init: 0.01\n",
      "CLF Score on training set: 0.9798\n",
      "CLF Score on test set: 0.9250\n",
      "Accuracy score: 0.9250\n",
      "--------------------------------------------------\n",
      "Experiment with learning rate init: 0.05\n",
      "CLF Score on training set: 1.0000\n",
      "CLF Score on test set: 0.9417\n",
      "Accuracy score: 0.9417\n",
      "--------------------------------------------------\n",
      "Experiment with learning rate init: 0.1\n",
      "CLF Score on training set: 0.8177\n",
      "CLF Score on test set: 0.7667\n",
      "Accuracy score: 0.7667\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate_init_list = [0.01, 0.05, 0.1]\n",
    "\n",
    "for lri in learning_rate_init_list:\n",
    "    clf=MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=200, learning_rate_init=lri, verbose=0, random_state=1)\n",
    "    \n",
    "    clf.fit (X_train,y_train)\n",
    "    print(f'Experiment with learning rate init: {lri}')\n",
    "    print(f'CLF Score on training set: {clf.score(X_train, y_train):.4f}')\n",
    "    print(f'CLF Score on test set: {clf.score(X_test, y_test):.4f}')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f'Accuracy score: {accuracy_score(y_test, y_pred):.4f}')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c3761",
   "metadata": {},
   "source": [
    "## Experiment 3 - adjusting max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cead6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with max iter: 50\n",
      "CLF Score on training set: 0.9896\n",
      "CLF Score on test set: 0.9278\n",
      "Accuracy score: 0.9278\n",
      "--------------------------------------------------\n",
      "Experiment with max iter: 100\n",
      "CLF Score on training set: 1.0000\n",
      "CLF Score on test set: 0.9444\n",
      "Accuracy score: 0.9444\n",
      "--------------------------------------------------\n",
      "Experiment with max iter: 200\n",
      "CLF Score on training set: 1.0000\n",
      "CLF Score on test set: 0.9417\n",
      "Accuracy score: 0.9417\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_iter_list = [50, 100, 200]\n",
    "\n",
    "for mi in max_iter_list:\n",
    "    clf=MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=mi, learning_rate_init=0.05, verbose=0, random_state=1)\n",
    "    \n",
    "    clf.fit (X_train,y_train)\n",
    "    print(f'Experiment with max iter: {mi}')\n",
    "    print(f'CLF Score on training set: {clf.score(X_train, y_train):.4f}')\n",
    "    print(f'CLF Score on test set: {clf.score(X_test, y_test):.4f}')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f'Accuracy score: {accuracy_score(y_test, y_pred):.4f}')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a93c48",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072fd32",
   "metadata": {},
   "source": [
    "The MLPClassifier class from skikit-learn library was used to build a neural network model for image classificaion. The model performance was optimized by adjusting the hyperparameters e.g., the number of hidden layers, the learning rate, and the number of iterations. Other hyperparameters can also be modified e.g. the number of neurons in each layer and evaluating the model's performance e.g. overfitting.\n",
    "\n",
    "Metrics were conducted to assess model accuracy, which performed well. Having learned to use the MLPClassifier classifier to train a neural network model on the MNIST dataset, which contained images of handwritten digits, the model can now be applied to recognize handwritten digits with a high degree of accuracy.\n",
    "\n",
    "Best hyperparameter performers:\n",
    "- Hidden layer sizes: 100, 10\n",
    "- Learning rate: 0.05\n",
    "- Max iter: 100\n",
    "\n",
    "The MLPClassifier is a powerful tool for building nueral network models for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5724b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
