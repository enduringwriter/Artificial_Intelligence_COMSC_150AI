{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cea78f-90f6-4d59-ac09-5eb15907bb1c",
   "metadata": {},
   "source": [
    "## Supervised learning using Regression\n",
    "\n",
    "## Predicting Price\n",
    "\n",
    "## Objectives\n",
    "\n",
    "On completing this assignment, you will learn how to write a simple AI application involving supervised learning using regression.\n",
    "\n",
    "## Description\n",
    "\n",
    "Write an AI application which, when provided with a diamond's attributes, will predict its price. For training and testing the application, please use the labeled data set provided in the file, sb_diamonds.csv. The data set contains data regarding 53940 diamonds with 10 attributes each including the price. Use 80% of the data items for training, and the remaining 20% for testing. Use the sklearn's Linear Regression (LinearRegression) model for training. After the model is trained, test it using the test data and produce the Mean Absolute Percentage Error (MeanAbsolutePercentageError) (MAPE) reflecting its performance. Also produce trained model's coefficient (coeff_) and intercept (intercpt_) values. \n",
    "\n",
    "#### Regressor models to be used\n",
    "\n",
    "Altogether, try out the following regression models of sklearn's library and compare their performance using Mean Absolute Percentage Error (MAPE) values.\n",
    "\n",
    "- Linear Regressor (LinearRegression) from sklearn,linear_model\n",
    "\n",
    "- KNeighbor Regressor (KNeighborRegressor) from sklearn.neighbors (using n_neighbors=5)\n",
    "  \n",
    "- Support Vector Regressor (SVR) from sklearn.svm\n",
    "  \n",
    "- Random Forest Regressor (RandomForestRegressor) from sklearn.ensemble \n",
    "\n",
    "#### Individual Values\n",
    "\n",
    "Also, try out made-up attribute values of a few diamonds with the best performing model from the above list and report the attribute values used and predicted prices received from the model.\n",
    "\n",
    "## Implementation \n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "- Remove rows containing missing or null values\n",
    "- Remove duplicate rows\n",
    "\n",
    "#### Columns Used\n",
    "\n",
    "Use all columns provided.\n",
    "\n",
    "#### Column Cleaning\n",
    "\n",
    "- carat, depth, table, price, x, y, z, and price column values are already numerical. So, leave them as they are.\n",
    "  \n",
    "- cut and clarity column values seem to be ordinal type. So, we need to convert them into numerical values using sklearn.preprocessing's label encoder (LabelEncoder).\n",
    "  \n",
    "- color column values seem to be nominal type. So, we need to convert them into numerical values using panda's getdummies function (using one hot decoding).\n",
    "\n",
    "## Discussion\n",
    "\n",
    "#### Column Data Types\n",
    "\n",
    "Data values are of either quantitative or qualitative type.\n",
    "\n",
    "#### Quantitative (Numerical) Values\n",
    "\n",
    "We can recognize quantitative (numrical) type values from the fact that they can be shown along a number line and we can perform mathematical operations (+, -, *, /) on them. The quantitative (numerical) type values can be either of discrete or continuous type.\n",
    "\n",
    "##### Continuous Values\n",
    "\n",
    "When quantitative (numerical) type values are along a number line within a range and all possible values within the range are permitted, then they are considered to be of continuous type. For example, height and weight size values are considered continuous because all weight and height values with a range are permitted.\n",
    "\n",
    "##### Discrete Values\n",
    " \n",
    "When quantitative (numerical) type values are along a number line within a range but some values  within the range are not included, then they are considered to be of discrete type. For example clothes and shoe size values are considered discrete because only certain clothes and shoe sizes exist within a range. \n",
    "\n",
    "For differentiating between discrete and continuous type values, consider shoe size and foot size values. Shoe size values are considered discrete because only certain shoe size values are permitted (the shoe size values of 8.11, 8.12 etc. do not exist). On the other hand, foot size values are considered continuous because we can specify a foot size of any value within a range\n",
    "\n",
    "Regressors versus Classifiers \n",
    "\n",
    "In our supervised learning problems, if the target (label) values are continuous such as prices (a price can have any value within the range)then we use regressors to solve them. However, when the target can have only certain values or can belong to certain categories, we use classifiers to solve them.\n",
    "\n",
    "\n",
    "#### Qualitative (Categorical) (Non-numerical) Values\n",
    "\n",
    "We can recognize Qualitative (Categorical) (non-numerical) type values from the fact that they can be shown along a number line and we cannot perform mathematical operations (+, -, *, /) on them. The quantitative (numerical) type values can be either of nominal or ordinal type.\n",
    "\n",
    "##### Nominal Values\n",
    " \n",
    "When data values are just names without any ranking or order to them, they are considered nominal values. For example, if a hair-color column contains values such as black, brown, red etc., then these value are considered nominal values because there is no ranking attached to these values. \n",
    "\n",
    "##### Ordinal Values\n",
    "\n",
    "When data values are names but there is an implied ranking or order attached to them, they are considered ordinal values. For example, if a job satisfaction column contains values such as unsatisfied, satisfied, very satisfied etc. then these values are considered ordinal values because there is an implied ranking or order attached to them.\n",
    "\n",
    "Implementing nominal and ordinal values\n",
    "\n",
    "In our problem, both nominal and ordinal column values are converted to numerical values. For converting nominal values, we use Pandas' getdummies method. It creates a separate column for each different name value. So, in our hair color example above, it will create a column for \"black', a column for \"brown\", and a column for \"red\" etc. and assign 0 or 1 in each column indicating the presence or absent of that color in the individual. \n",
    "\n",
    "On the other hand, for an ordinal column value, we use sklearn.preprocessing module's label encoder (LabelEncoder). The encoder does not create any new columns. Instead, it substitutes value 0, 1, 2, 3, etc for different ordered name values. \n",
    "\n",
    "\n",
    "## Implementation Notes\n",
    "\n",
    "\n",
    "#### Dataset source\n",
    "\n",
    "The data set was downloaded fity-data-determining-factors\n",
    "\n",
    "\n",
    "## Submittal\n",
    "\n",
    "The uploaded submittal should contain the following:\n",
    "\n",
    "- jpynb file after running the application from start to finish containing the marked source code, output, and your interaction.\n",
    "  \n",
    "- the corresponding html file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d3437",
   "metadata": {},
   "source": [
    "## Keith Yrisarri Stateson\n",
    "June 23, 2024. Python 3.11.0\n",
    "\n",
    "## Title: Predicting Diamond Prices Using Various Regression Models - Supervised Learning\n",
    "\n",
    "## Summary\n",
    "This program is an AI application to predict the prices of Diamonds based on their attributes. Supervised learning and regression techniques are used to train and evaluate multiple models on a provided dataset, predict diamond prices for new, made-up attributes, and assess model accuracy using MAPE. The goal is to determine which model performs best in predicting diamond prices and to understand the influence of various features on the price.\n",
    "\n",
    "#### Assumption\n",
    "Columns x, y, z are length, width, depth (height) of the diamond.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "Part 1: DataFrame Cleaning\n",
    "\n",
    "Part 2: Evaluate the Features and Target variable\n",
    "\n",
    "Part 3: Data Cleaning\n",
    "\n",
    "Part 4: Feature Engineering\n",
    "\n",
    "Part 5: Train-Test Split and Feature Scaling\n",
    "\n",
    "Part 6: Modeling\n",
    "- Linear Regression Model\n",
    "- Random Forest Regressor Model\n",
    "- KNN Model\n",
    "- SVR Model\n",
    "\n",
    "Part 7: Identify the best performing model to predict diamond prices\n",
    "\n",
    "Part 8: Predict Diamond Prices with New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245059a0",
   "metadata": {},
   "source": [
    "## Part 1: DataFrame Cleaning\n",
    "\n",
    "Evaluate the dataframe for missing values, empty rows and columns, and duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "44762fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "df=pd.read_csv('sb_diamonds.csv',index_col=0)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9d56da64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0\n",
       "cut        0\n",
       "color      0\n",
       "clarity    0\n",
       "depth      0\n",
       "table      0\n",
       "price      0\n",
       "x          0\n",
       "y          0\n",
       "z          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "75ead0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of missing values across all rows and columns in the entire dataframe. It does not indicate\n",
    "# the number of empty rows directly, but rather the total number of missing entries in the dataframe.\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eaf78249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Rows:  Empty DataFrame\n",
      "Columns: [carat, cut, color, clarity, depth, table, price, x, y, z]\n",
      "Index: []\n",
      "Empty Columns: []\n"
     ]
    }
   ],
   "source": [
    "# Find empty rows (rows where all elements are NaN)\n",
    "empty_rows = df[df.isna().all(axis=1)]\n",
    "print('Empty Rows: ', empty_rows)\n",
    "\n",
    "# Find empty columns (columns where all elements are NaN)\n",
    "empty_columns = df.columns[df.isna().all()].tolist()\n",
    "print(\"Empty Columns:\", empty_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fa75b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "\n",
    "# Verifiy that there are no rows with missing values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "64068694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:        carat    cut color clarity  depth  table  price     x     y     z\n",
      "1005    0.79  Ideal     G     SI1   62.3   57.0   2898  5.90  5.85  3.66\n",
      "1006    0.79  Ideal     G     SI1   62.3   57.0   2898  5.90  5.85  3.66\n",
      "1007    0.79  Ideal     G     SI1   62.3   57.0   2898  5.90  5.85  3.66\n",
      "1008    0.79  Ideal     G     SI1   62.3   57.0   2898  5.90  5.85  3.66\n",
      "2025    1.52   Good     E      I1   57.3   58.0   3105  7.53  7.42  4.28\n",
      "...      ...    ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
      "47969   0.52  Ideal     D     VS2   61.8   55.0   1919  5.19  5.16  3.20\n",
      "49326   0.51  Ideal     F    VVS2   61.2   56.0   2093  5.17  5.19  3.17\n",
      "49557   0.71   Good     F     SI2   64.1   60.0   2130  0.00  0.00  0.00\n",
      "50079   0.51  Ideal     F    VVS2   61.2   56.0   2203  5.19  5.17  3.17\n",
      "52861   0.50   Fair     E     VS2   79.0   73.0   2579  5.21  5.18  4.09\n",
      "\n",
      "[146 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print('Duplicate Rows:', duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40987ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53794, 10)\n",
      "Duplicate Rows: Empty DataFrame\n",
      "Columns: [carat, cut, color, clarity, depth, table, price, x, y, z]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)\n",
    "\n",
    "# Verify that there are no duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print('Duplicate Rows:', duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b4bda371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   carat      cut color clarity  depth  table  price     x     y     z\n",
      "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
      "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
      "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n"
     ]
    }
   ],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55961c37",
   "metadata": {},
   "source": [
    "## Part 2: Evaluate the Features and Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "50212934-9891-42cc-b2d1-203e93a15ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price\n",
       "605      132\n",
       "802      126\n",
       "625      125\n",
       "776      124\n",
       "828      124\n",
       "        ... \n",
       "14683      1\n",
       "14680      1\n",
       "14675      1\n",
       "8812       1\n",
       "9793       1\n",
       "Name: count, Length: 11602, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the unique values in the 'price' column\n",
    "df['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "494c816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat\n",
       "0.30    2596\n",
       "1.01    2240\n",
       "0.31    2238\n",
       "0.70    1981\n",
       "0.32    1827\n",
       "        ... \n",
       "3.02       1\n",
       "3.65       1\n",
       "3.50       1\n",
       "3.22       1\n",
       "3.11       1\n",
       "Name: count, Length: 273, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'carat'\n",
    "df['carat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e48b2a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cut\n",
       "Ideal        21488\n",
       "Premium      13748\n",
       "Very Good    12069\n",
       "Good          4891\n",
       "Fair          1598\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'cut'\n",
    "df['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "54a87e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color\n",
       "G    11262\n",
       "E     9776\n",
       "F     9520\n",
       "H     8272\n",
       "D     6755\n",
       "I     5407\n",
       "J     2802\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'color'\n",
    "df.color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4973bbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clarity\n",
       "SI1     13032\n",
       "VS2     12229\n",
       "SI2      9150\n",
       "VS1      8156\n",
       "VVS2     5056\n",
       "VVS1     3647\n",
       "IF       1784\n",
       "I1        740\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'clarity'\n",
    "df.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "48947e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth\n",
       "62.0    2233\n",
       "61.9    2160\n",
       "61.8    2069\n",
       "62.2    2033\n",
       "62.1    2011\n",
       "        ... \n",
       "71.3       1\n",
       "44.0       1\n",
       "53.0       1\n",
       "53.1       1\n",
       "54.7       1\n",
       "Name: count, Length: 184, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the feature 'depth'\n",
    "df.depth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f4c681c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table\n",
       "56.0    9851\n",
       "57.0    9695\n",
       "58.0    8352\n",
       "59.0    6562\n",
       "55.0    6242\n",
       "        ... \n",
       "51.6       1\n",
       "63.5       1\n",
       "43.0       1\n",
       "62.4       1\n",
       "61.6       1\n",
       "Name: count, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'table'\n",
    "df.table.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3c25b4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x\n",
       "4.37     444\n",
       "4.34     436\n",
       "4.33     428\n",
       "4.38     426\n",
       "4.32     422\n",
       "        ... \n",
       "10.74      1\n",
       "9.36       1\n",
       "9.06       1\n",
       "8.89       1\n",
       "9.05       1\n",
       "Name: count, Length: 554, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'x'\n",
    "df.x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "69bd5b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "4.34     436\n",
       "4.37     432\n",
       "4.35     424\n",
       "4.33     420\n",
       "4.32     411\n",
       "        ... \n",
       "8.89       1\n",
       "10.16      1\n",
       "9.46       1\n",
       "9.63       1\n",
       "31.80      1\n",
       "Name: count, Length: 552, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'y'\n",
    "df.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "36ae13fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z\n",
       "2.70     761\n",
       "2.69     745\n",
       "2.71     733\n",
       "2.68     730\n",
       "2.72     691\n",
       "        ... \n",
       "5.86       1\n",
       "5.66       1\n",
       "5.72       1\n",
       "5.73       1\n",
       "31.80      1\n",
       "Name: count, Length: 375, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the feature 'z'\n",
    "df.z.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cc1ff",
   "metadata": {},
   "source": [
    "## Part 3: Data Cleaning - Features and Target variable\n",
    "\n",
    "*Conversion of Panda Series into a NumPy Array.*  \n",
    "Many machine learning libraries, such as scikit-learn, expect input data to be in the form of NumPy arrays rather than pandas Series.  \n",
    "Converting the target to a NumPy array ensures compatibility with these libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "510a84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No cleaning required for dataset values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05278e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    326\n",
      "1    326\n",
      "2    327\n",
      "Name: price, dtype: int64\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Assign the target variable\n",
    "target = df.price\n",
    "print(target.head(3))\n",
    "target = np.array(target)\n",
    "print(type(target))\n",
    "print(type(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6f4ed5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53794 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0  5.83  5.87  3.64\n",
       "\n",
       "[53794 rows x 9 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the features\n",
    "df_features = df.filter(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z'])\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f8415f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the features to a numpy array\n",
    "df_features.carat = np.array(df_features.carat)\n",
    "df_features.cut = np.array(df_features.cut)\n",
    "df_features.color = np.array(df_features.color)\n",
    "df_features.clarity = np.array(df_features.clarity)\n",
    "df_features.depth = np.array(df_features.depth)\n",
    "df_features.table = np.array(df_features.table)\n",
    "df_features.x = np.array(df_features.x)\n",
    "df_features.y = np.array(df_features.y)\n",
    "df_features.z = np.array(df_features.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c131584",
   "metadata": {},
   "source": [
    "## Part 4: Feature Engineering\n",
    "\n",
    "Transform nominal categorical data to numerical using pandas.get_dummies, and drop the catgorical column and add the newly created numerical version to the features dataframe.\n",
    "\n",
    "Transforms ordinal categorical data to numerical using the LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4165bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53794 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       E  F  G  H  I  J\n",
       "0      1  0  0  0  0  0\n",
       "1      1  0  0  0  0  0\n",
       "2      1  0  0  0  0  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  0  1\n",
       "...   .. .. .. .. .. ..\n",
       "53935  0  0  0  0  0  0\n",
       "53936  0  0  0  0  0  0\n",
       "53937  0  0  0  0  0  0\n",
       "53938  0  0  0  1  0  0\n",
       "53939  0  0  0  0  0  0\n",
       "\n",
       "[53794 rows x 6 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorial 'color' to numerical values using get dummies\n",
    "df_features_color_num = pd.get_dummies(df_features.color, dtype=int, drop_first=True)\n",
    "df_features_color_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1da9ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Ideal\n",
      "1    Premium\n",
      "2       Good\n",
      "Name: cut, dtype: object\n",
      "\n",
      "\n",
      "cut\n",
      "2    21488\n",
      "3    13748\n",
      "4    12069\n",
      "1     4891\n",
      "0     1598\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "{'Fair': 0, 'Good': 1, 'Ideal': 2, 'Premium': 3, 'Very Good': 4}\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'cut' feature using LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "print(df_features.cut.head(3))\n",
    "print('\\n')\n",
    "\n",
    "df_features.cut = le.fit_transform(df_features.cut)\n",
    "print(df_features.cut.value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# Visual mapping of Screen_resolution values to integers \n",
    "mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9700d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    SI2\n",
      "1    SI1\n",
      "2    VS1\n",
      "Name: clarity, dtype: object\n",
      "\n",
      "\n",
      "clarity\n",
      "2    13032\n",
      "5    12229\n",
      "3     9150\n",
      "4     8156\n",
      "7     5056\n",
      "6     3647\n",
      "1     1784\n",
      "0      740\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "{'I1': 0, 'IF': 1, 'SI1': 2, 'SI2': 3, 'VS1': 4, 'VS2': 5, 'VVS1': 6, 'VVS2': 7}\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'clarity' feature using LabelEncoder\n",
    "print(df_features.clarity.head(3))\n",
    "print('\\n')\n",
    "\n",
    "df_features.clarity = le.fit_transform(df_features.clarity)\n",
    "print(df_features.clarity.value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# Visual mapping of Screen_resolution values to integers \n",
    "mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b6517648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       carat  cut  clarity  depth  table     x     y     z  E  F  G  H  I  J\n",
      "0       0.23    2        3   61.5   55.0  3.95  3.98  2.43  1  0  0  0  0  0\n",
      "1       0.21    3        2   59.8   61.0  3.89  3.84  2.31  1  0  0  0  0  0\n",
      "2       0.23    1        4   56.9   65.0  4.05  4.07  2.31  1  0  0  0  0  0\n",
      "3       0.29    3        5   62.4   58.0  4.20  4.23  2.63  0  0  0  0  1  0\n",
      "4       0.31    1        3   63.3   58.0  4.34  4.35  2.75  0  0  0  0  0  1\n",
      "...      ...  ...      ...    ...    ...   ...   ...   ... .. .. .. .. .. ..\n",
      "53935   0.72    2        2   60.8   57.0  5.75  5.76  3.50  0  0  0  0  0  0\n",
      "53936   0.72    1        2   63.1   55.0  5.69  5.75  3.61  0  0  0  0  0  0\n",
      "53937   0.70    4        2   62.8   60.0  5.66  5.68  3.56  0  0  0  0  0  0\n",
      "53938   0.86    3        3   61.0   58.0  6.15  6.12  3.74  0  0  0  1  0  0\n",
      "53939   0.75    2        3   62.2   55.0  5.83  5.87  3.64  0  0  0  0  0  0\n",
      "\n",
      "[53794 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the categorical 'color' feature and replace it with numberical df_features_color_num\n",
    "df_features = df_features.drop('color', axis=1)\n",
    "df_features = pd.concat([df_features, df_features_color_num], axis=1)\n",
    "print(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60a3c1",
   "metadata": {},
   "source": [
    "## Part 5: Train-Test Split and Feature Scaling\n",
    "\n",
    "Assign features and target.  \n",
    "Split the dataset into 80% training, 20% testing.  \n",
    "Standardize the training and test feature data.  \n",
    "Apply the transformation to both the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "64351c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign featurs and the target variable, and split the data into training and test sets\n",
    "\n",
    "X = df_features\n",
    "y = target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "317d3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94345735 -0.54238513  0.67731271 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " [ 2.96422154 -0.54238513 -0.48265118 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " [-0.56529488 -0.54238513  0.67731271 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " ...\n",
      " [-1.00648443 -0.54238513 -1.06263312 ... -0.42625798 -0.33455838\n",
      "   4.26956936]\n",
      " [ 0.2120391   0.43196552 -1.06263312 ... -0.42625798 -0.33455838\n",
      "   4.26956936]\n",
      " [ 0.44313838  0.43196552  0.09733077 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]]\n",
      "\n",
      "\n",
      "[[-0.1871324  -2.49108644  0.67731271 ... -0.42625798 -0.33455838\n",
      "   4.26956936]\n",
      " [ 0.2120391   1.40631617 -0.48265118 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " [-0.48125877 -0.54238513  0.09733077 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " ...\n",
      " [-1.00648443 -0.54238513  1.25729466 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " [ 1.55661678  0.43196552  0.67731271 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]\n",
      " [-0.94345735  0.43196552  1.25729466 ... -0.42625798 -0.33455838\n",
      "  -0.23421566]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features using StandardScaler and fit the scaler to the training data, and transform the test data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a64e4",
   "metadata": {},
   "source": [
    "## Part 6: Modeling\n",
    "\n",
    "Linear Regression  \n",
    "Random Forest Regressor  \n",
    "KNN Model  \n",
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b2c8fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prices (Linear Regression): [1387.58056255 4721.46090486 2217.3873344  1800.45752497 5873.31106769\n",
      "   73.83998816  465.33499263 1977.01980533 1026.68609899 4575.49973261]\n",
      "\n",
      "\n",
      "Predicted Prices (RandomForest): [1682.78 3696.55 1868.14 1630.1  5284.52  633.48  470.58 2315.18 1058.54\n",
      " 4801.71]\n",
      "\n",
      "\n",
      "Predicted Prices (KNeighbors): [1417.2 3952.2 1824.6 1646.4 5240.   668.4  549.6 2200.8 1764.4 4674. ]\n",
      "\n",
      "\n",
      "Predicted Prices (SVR): [2984.22347221 3664.41342034 1885.32636926 1717.99141832 4447.08151184\n",
      "  847.76012863  321.75187697 2736.31189265 1781.4912965  4238.27023873]\n",
      "\n",
      "\n",
      "Actual Prices: [1435 3584 1851 1590 5690  596  492 2063  970 4796]\n"
     ]
    }
   ],
   "source": [
    "# Train the model using Linear Regression, RandomForestRegressor, KNeighborsRegressor, and SVR, and make predictions\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# SVR\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using Linear Regression\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "# y_pred_lr = np.maximum(0, y_pred_lr)  # This only corrects the output after the prediction, but it doesn't address\n",
    "# the underlying issue with the model training and feature engineering.\n",
    "print(f'Predicted Prices (Linear Regression): {y_pred_lr[:10]}')\n",
    "print('\\n')\n",
    "\n",
    "# Prediction using RandomForestRegressor\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "# y_pred_rf = np.maximum(0, y_pred_rf)\n",
    "print(f'Predicted Prices (RandomForest): {y_pred_rf[:10]}')\n",
    "print('\\n')\n",
    "\n",
    "# Prediction using KNeighborsRegressor\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "# y_pred_knn = np.maximum(0, y_pred_knn)\n",
    "print(f'Predicted Prices (KNeighbors): {y_pred_knn[:10]}')\n",
    "print('\\n')\n",
    "\n",
    "# Prediction using SVR\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "# y_pred_svr = np.maximum(0, y_pred_svr)\n",
    "print(f'Predicted Prices (SVR): {y_pred_svr[:10]}')\n",
    "print('\\n')\n",
    "\n",
    "# Print the actual prices of the test set\n",
    "print(f'Actual Prices: {y_test[0:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c783783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAPE: 0.36533548596427373\n",
      "RandomForestRegressor MAPE: 0.06696369185391982\n",
      "KNeighborsRegressor MAPE: 0.11579333475616\n",
      "SVR MAPE: 0.37367955328281194\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAPE for each model\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Calculate MAPE for Linear Regression\n",
    "mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "print(f'Linear Regression MAPE: {mape_lr}')\n",
    "\n",
    "# Calculate MAPE for RandomForestRegressor\n",
    "mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
    "print(f'RandomForestRegressor MAPE: {mape_rf}')\n",
    "\n",
    "# Calculate MAPE for KNeighborsRegressor\n",
    "mape_knn = mean_absolute_percentage_error(y_test, y_pred_knn)\n",
    "print(f'KNeighborsRegressor MAPE: {mape_knn}')\n",
    "\n",
    "# Calculate MAPE for SVR\n",
    "mape_svr = mean_absolute_percentage_error(y_test, y_pred_svr)\n",
    "print(f'SVR MAPE: {mape_svr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206db5e",
   "metadata": {},
   "source": [
    "## Part 7: Identify the best performing model to predict mobile phone prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8480f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model is: RandomForestRegressor with MAPE: 0.06696369185391982\n"
     ]
    }
   ],
   "source": [
    "# Best model based on MAPE\n",
    "mape_values_dict = {'Linear Regression': mape_lr, 'RandomForestRegressor': mape_rf, 'KNeighborsRegressor': mape_knn, 'SVR': mape_svr}\n",
    "print(f'Best Model is: {min(mape_values_dict, key=mape_values_dict.get)} with MAPE: {min(mape_values_dict.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a628b8c",
   "metadata": {},
   "source": [
    "## Part 8: Predict Diamond Prices with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7542fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396.15]\n",
      "[467.6]\n",
      "[2279.08009674]\n",
      "[1189.47392309]\n"
     ]
    }
   ],
   "source": [
    "# carat  cut  clarity  depth  table     x     y     z  E  F  G  H  I  J\n",
    "sc_new_data = sc.transform([[0.33, 2, 3, 61.5, 55.0, 3, 3, 2, 1, 0, 0, 0, 0, 0]])\n",
    "print(rf_model.predict (sc_new_data))\n",
    "print(knn_model.predict (sc_new_data))\n",
    "print(lr_model.predict (sc_new_data))\n",
    "print(svr_model.predict (sc_new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
