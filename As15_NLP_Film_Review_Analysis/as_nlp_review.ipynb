{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c62a21-9d19-4563-af35-985375303f07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Natural Language Processing (NLP) & Neural Networks\n",
    "\n",
    "## Text Sentiment\n",
    "\n",
    "### Predicting sentiment in film reviews using neural networks\n",
    "\n",
    "### Objectives\n",
    "\n",
    "On completing this assignment, you will be able to write a simple AI application for classifying film reviews into positive and negative sentiment review using neural networks.\n",
    "\n",
    "### Readings for Neural Networks\n",
    "\n",
    "Required: Introduction\n",
    "https://www.ibm.com/topics/neural-networks#:~:text=One%20of%20the%20best%2Dknown,heart%20of%20deep%20learning%20models\r\n",
    "Optional: Backpropagation\n",
    "\r\n",
    "https://www.geeksforgeeks.org/backpropagation-in-neural-networ\n",
    "\n",
    "Required: (code example)ode\r\n",
    "https://www.pluralsight.com/resources/blog/guides/machine-learning-neural-networks-scikit-learn#:~:text=In%20this%20guide%2C%20you%20have,training%20and%20test%20data%2C%20respectiv\n",
    "et### Assignment\n",
    "ption\n",
    " \n",
    "Write an AI application which will classify film reviews into positive and negative reviews. The data set (corpus) used for the assignment and the steps to follow are described below.\n",
    "\n",
    "### Data set (corpus) used for the application\n",
    "\n",
    "Use the data set (corpus) in the following file:\n",
    "\n",
    "\"imdb_5k_reviews.csv\"\n",
    "\n",
    "### Load the data set\n",
    "\n",
    "Load the data files into pandas data frames as shown below.\n",
    "\n",
    "    import pandas as pd\n",
    "    df=pd.read_csv(\"imdb_5k_reviews.csv\",index_col=0)\n",
    "\n",
    "### Assign sentiment column to y and review column to X\n",
    "\n",
    "- Assign the sentiment column to variable y (the labels).\n",
    "- Assign the review column to variable X (the features). \n",
    "\n",
    "### Clean \n",
    "p text\n",
    "\n",
    "Cleanup X containing reviews as below\n",
    "\n",
    "- remove all html tags\n",
    "- remove all quotations etc. between a pair of square brackets.\n",
    "- remove all special characters (remove all characters except alphabets, digits, and space characteCleanup codes)\n",
    "  \n",
    "i\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import nltk\n",
    "    \n",
    "    def cleanup (text):\n",
    "        #Remove the html strips\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "     \n",
    "        #Remove between square brackets   \n",
    "        text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    \n",
    "        #remove special characters\n",
    "        pattern=r'[^a-zA-Z0-9\\s]'\n",
    "        text=re.sub(pattern,' ',text)\n",
    "        text = re.sub (r'\\s+', ' ', text)\n",
    "        return text\n",
    "        \n",
    "    X = X.apply(cleanup)\n",
    "\n",
    "\n",
    "### Vectorize data\n",
    "\n",
    "Vectorize data using TfidfVectorizer. The data passed to the vectorizer should be either a pandas Series object or list object or similar iterable object. \n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(max_features=2000, min_df=5,  max_df=0.7, \\\n",
    "                 stop_words=stopwords.words('engl\n",
    "                 ish') )\n",
    "    X_vectorized= tfidf_vect.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "### Split datait_vetorized and y a X, y into train an tes(X_train, X_test, y_train, and y_test) t data using train_test_split function of sklearn.model_selection module with 80% for t and the remaining for testing.raining\n",
    "\n",
    "### Training\n",
    "\n",
    "For training, use MLPClassifier classifier of sklearn.neural_network module that employs neural networks. Its input level size is always the same as the number of inputs. The output level size is always the same as the number of outputs. \n",
    "\n",
    "Below, we choose the hidden level size to be 10 and we leave the number of hidden levels to be unspecified (10, ). So the classifier will choose the number of hidden levels. \n",
    "\n",
    "Below, we specify the maximum iteration to be 50. So, during training, the classifier (clf) will run the same data 50 times, changing its internal weight parameters each time, trying to reduce the loss (error) (the average difference between the actual output values and the predicted value). \n",
    "\n",
    "Below, we specify verbose as 1. So, during the training, at the end of each run, the classifiers  will print the loss (error) value and we will be able to sethe e that loss value is going down after each run but will not reach ero. \n",
    "\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf=MLPClassifier(hidden_layer_sizes=(10,), max_iter=50, verbose=1, random_state=1)\n",
    "    clf.fit (X_train,y_train)\n",
    "\n",
    "### Testing\n",
    "\n",
    "Test the trained classifier with testing data\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "### Print scores\n",
    "\n",
    "Print the score of running the trained classifier on the training data and the test data. Since the loss (error) after runntimes0 epoch is still not zero that means runniscore of running the ng the trained classnfier of the trainia score will not (100%) be 1.0. Beltry to ow, we display the score after running the trained classn thefier of training data and test data.\n",
    "\n",
    "    print (clf.score(X_train,y_train))\n",
    "    print (clf.score(X_test,y_test))\n",
    "\n",
    "###AdditionalFurthers Result\n",
    "\n",
    "Print accuracy score, classification report, and confusion matrix\n",
    "\n",
    "### Test Single Film Reviews\n",
    "\n",
    "Test a few made-up film reviews using the trained classifier and print the results. Try the following:\n",
    "\n",
    "    print(clf.predict(tfidf_vect.transform([cleanup(\"It is a good movie\")])))\n",
    "    print(clf.predict(tfidf_vect.transform([cleanup(\"It was a bad film\")])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003f8bb-2c2c-451f-a0f4-f37d5f4cc682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948add3-2cfe-4f8d-86d3-12b9c04a6241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
